\section{Design}
\label{sec:design}

\subsection{General framework}
In CRAQamo, each read or write request is given a tag of consistency requirement: strong or eventual. Strongly consistent reads and writes are performed as standard CRAQ operations. Enventually consistent read requests can go to any node in the chain like CRAQ, but the most recent data is returned before confirming that every server has updated to that value. Enventually consistent write requests can be served by any node as well, but the written value is send to other servers using ``multicast'' instead of propagating from the head node to the tail node. In practice we define values, $W$ and $R$. Before a server responds to a read request, it must synchronize with the other servers and wait to return until there are at least $R$ successful responses, then reply back to the user.  Before a server responds to a write request, it must synchronize with other servers and wait until there are at least $W$ successful responses. Effectively we implemented a system where a certain number of participants must agree on a value before it can be committed. With both strongly and eventually consistent operations supported in CRAQamo we can meet the the users' consistency and performance requirements in different application scenarios using a single infrastructure. 

Intuitively, lowering the consistency constraint to eventual consistency can help us achieve much better write latency and throughput. However, the read performance may degrade slightly due do pair-wise communications between servers to compare data versions. The improvements and overheads will be presented quantitatively in our evaluations. The performance advantage of eventual consistency becomes more obvious as we increase the communication latency between servers to simulate data centers that spread around the globe. We modified the CRAQ source code and implemented data propagation and synchronization procedures using the same RPC interface as CRAQ. The network latency is controlled by port forwarding using ``ncat'' program which is able to redirect data from one network port to another while adding a controlled amount of latency.

\subsection{Original CRAQ capabilities}
Our system is built upon CRAQ, thus it has the full capabilities of CRAQ. CRAQ naturally supports strongly consistent reads and writes. We keep the strongly consistent storage interfaces in CRAQ and leave an additional flag for the user to determine whether to apply strongly consistent operations. We also adopt the failure recovery mechanism in CRAQ.

\subsection{Internal methods}
{\noindent \bf Broadcasting data\ \ } In CRAQ, data is only passed between neighboring nodes, which causes the write operations to be inefficient because each write operation needs to go through all the nodes although strong consistency is guaranteed. In CRAQamo, when strong consistency is not a must, we allow direct communication between any two nodes. Specifically, we have an internal method called ``eventual consistency propagate'' to help pass information globally among all the nodes. We show the necessity of having this internal helper method in the following sections. \\

{\noindent \bf Comparing versions\ \ } Like CRAQ, each node in the chain also store multiple versions of objects in CRAQamo. CRAQ uses a monotonically-increasing number as the version number, which is local to the node. Synchronization is not a problem to CRAQ since, as we mentioned previously, data is only passed between neighboring nodes. However, such a simple representation for the version cannot handle global broadcasting and race conditions well. Instead, CRAQamo uses global timestamps to represent versions. We would like to emphasize that replacing monotonically-increasing version numbers with timestamps do not affect the original functionalities of CRAQ, thus strongly consistent operations are still supported by CRAQ and we do not discuss them in detail here.

For eventually consistent operations, we need to remotely compare versions of objects between nodes. Therefore it is necessary for each node to fetch the newest timestamps on other nodes and determine if either node needs to be updated. Specifically, a node requests other nodes for their current timestamps. Since the timestamps are global, comparison can be easily done by comparing the actual values of timestamps (larger value means newer and vice versa). Such a version comparing method also serves as an internal helper method and we detail the usages in the following sections. 

\subsection{Eventually consistent read}
Eventual consistency allows read operations to return newly written objects before they are fully synchronized among all nodes. This is the key to reducing the read latency compared to CRAQ because CRAQ is constrained by the strong consistency capability, thus only committed objects can be returned. In the eventual consistency mode of CRAQamo, the newly written object can be directly returned to the requester as long as the timestamp of the object is sufficiently new. Note that it is not strictly required that the timestamp of the object on the current node is the newest. We apply a Dynamo style parameter $R$ so that the user can determine the level of eventual consistency.

When an eventually consistent read operation is performed on a node. The node first compares the timestamp of the requested object with the timestamps of the object on all other nodes. To speed up the process, the comparisons are done in parallel. Once $R$ other nodes agree that the current node has the newer version of object, the current node directly returns the object to the user. If any of the $R$ nodes disagree that the current node has the newest version of object, the requesting node updates itself to the most recent version. If any of the other nodes are not up to date, the requesting node sends an ``eventual consistency propagate'' request to that node.  By varying $R$, the level of eventual consistency can be flexibly tuned. For example, lowering $R$ requires fewer nodes to be synchronized before returning to the client so that the overall read latency can be reduced.

\subsection{Eventually consistent write}
A critical reason that chain replication storage systems are generally slow in write operations is that the write operation needs to go through all the nodes in the chain. While this guarantees strong consistency, the latency is also large when the latency between nodes is large. However, if strong consistency is not a must, one can choose to write new data to any node in the chain instead of writing to the head node. In CRAQamo, we allow the user to write to any node and safely check whether there are other writes performed on other nodes when the write operation is being performed. Note that write operations happening almost concurrently on multiple nodes rarely occurs, so the synchronization can take slightly longer time and it will not critically affect the overall write performance.

When an eventually consistent write operation is performed on a node. The node first takes the input object, writes it locally and attaches a timestamp to the updated object. It then calls ``eventual consistency propagate'' to broadcast that new value to the other nodes.  When the other nodes receive that propagation, they confirm the sent version is the latest.  If it is, they write the value and return, but if it isn't, they propagate their value to the node that sent the original propagate.  After the original node agrees on the new value and returns from the propagate, the target node returns successfully. Once the original node has reached a consensus with $W$ other nodes, it returns a success to the client, and continues the propagation algorithm with the remaining nodes. 

\subsection{Implementation}
Our prototype implementation of CRAQamo was implemented in approximately 3700 lines of C++,
built upon the a prototype implementation of CRAQ implemented in approximately 3000 lines of C++.
Like CRAQ, CRAQamo uses the Tame \cite{tame} extension to the SFS asynchronous I/O and RPC libraries \cite{sfs} and all network functionality between CRAQamo RPC nodes is exposed via Sun RPC interfaces.
Unlike CRAQ, CRAQamo also uses the built in C++ multithreading library.
To implement the broadcast reads and writes for consistency checks, CRAQamo needs to spin up multiple threads, and wait until $w$ of them complete their calls before returning.
Even after returning, however, CRAQamo needs to continue the consistency checks for the nodes that have not completed.
This proved too difficult of a pattern to express in Tame, so we instead built our own manner of multithreading for these checks.
However, for all other asynchronous calls, we used Tame to decrease code complexity.

Our integration with ZooKeeper was provided with by the expansion of CRAQ, and was integrated in the same way, with CRAQamo nodes able to query the same ZooKeeper files as CRAQ nodes.
Furthermore, expansion of CRAQ gave us free chain node functionality and the ability to handle membership changes dynamically.
Because data is stored in the same manner as CRAQ, and because no node has special knowledge in CRAQamo, CRAQ's algorithm for membership changes proves sufficient for CRAQamo.
