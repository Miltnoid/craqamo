\vspace{-2mm}
\section{Design}
\label{sec:design}

\subsection{General framework}
In CRAQamo, each read or write request is given a tag of consistency requirement: strong or eventual. Strongly consistent reads and writes are performed as standard CRAQ operations. Enventually consistent read requests can go to any node in the chain like CRAQ, but the most recent data is returned before confirming that every server has updated to that value. Enventually consistent write requests can be served by any node as well, but the written value is send to other servers using ``multicas'' instead of propagating from the head node to the tail node. In practice we define a value, $k$ such that before a server respond to any request, it must synchronize other servers and wait until there is at least $k$ successful responses, then reply back to the user. Effectively we implemented a system where a certain number of participants must agree on a value before it can be committed. With both strongly and eventually consistent operations supported in CRAQamo we can meet the the users' consistency and performance requirements in different application scenarios using a single infrastructure. \\

Intuitively, lowering the consistency constraint to eventual consistency can help us achieve much better write latency and throughput, however, the read performance may degrade slightly due do pair-wise communications between servers to compare data versions. The improvements and overheads will be presented quantitatively in our evaluations. The performance advantage of eventual consistenty becomes more obvious as we increase the communication latency between servers to simulate data centers that spread around the globe. We modified the CRAQ source code and implemented data propagation and synchronization procedures using the same RPC interface as used originally. The network latency is controlled by port forwarding using ``ncat" program which is able to redirect data from one network port to another while adding a controlled amount of latency.

\subsection{Original CRAQ capabilities}
Our system is built upon CRAQ, thus it has the full capabilities of CRAQ. CRAQ naturally supports strongly consistent read and write. We keep the strongly consistent storage interfaces in CRAQ and leave an additional flag for the user to determine whether to apply strongly consistent operations. We also adopt the failure recovery mechanism in CRAQ.

\subsection{Broadcasting data}
In CRAQ, data is only passed between neighboring nodes, which causes the write operation inefficient because each write operation needs to go through all the node although strong consistency is guaranteed. In CRAQamo, when strong consistency is not a must, we allow direct communication between any two nodes. Specifically, we have an internal method called ``eventual consistency propagat'' to help pass information globally among all the nodes. We show the necessity of having this internal helper method in the following sections.

\subsection{Comparing versions}
Like CRAQ, each node in the chain also store multiple versions of objects in CRAQamo. CRAQ uses a monotonically-increasing number as the version number, which is local to the node. Synchronization is not a problem to CRAQ since as we mentioned previously, data is only passed between neighboring nodes. However, such a simple representation for the version cannot handle global broadcasting well. Instead, CRAQamo uses global timestamps to represent versions. We would like to emphasize that replacing monotonically-increasing version numbers with timestamps do not affect the original functionalities of CRAQ, thus strongly consistent operations are still supported by CRAQ and we do not discuss them in detail here.

For eventually consistent operations, we need to remotely compare versions of objects between nodes. Therefore it is necessary for each node to fetch the newest timestamps on other nodes and return boolean values indicating whether the current node keeps the newest version of the object of interest. Specifically, a node signals other nodes to return their current timestamps. Since the timestamps are global, comparison and be easily done by comparing the actual values of timestamps (larger value means newer and vice versa). Such version comparing method also severs as an internal helper method and we detail the usages in the following sections. 

\subsection{Eventually consistent read}
Eventual consistency allows read operations to return newly written objects before they are fully synchronized among all nodes. This is the key to reducing the read latency comparing with CRAQ because CRAQ is constrained by the strong consistency capability, thus only committed objects can be returned. In the eventual consistency mode of CRAQamo, the newly written object can be directly return to the requester as long as the timestamp of the object is sufficiently new. Note that it is not strictly required that the timestamp of the object on the current node is the newest. We apply a Dynamo style parameter $R$ so that the user can determine the level of eventual consistency.

When an eventually consistent read operation is performed on a node. The node first compares the timestamp of the requested object with the timestamps of the object on all other nodes. To speed up the process, the comparisons are done in parallel. Once there are $R$ other nodes agree that the current node has the newer version of object, the current node directly returns the object to the user. If any of the $R$ nodes disagrees that the current node has the newest version of object, ``eventual consistency propagate'' is executed so that the newer object can be passed from the node which is holding the newer version of object to the current node. By varying $R$, the level of eventual consistency can be flexibly tuned. For example, lowering $R$ lowers the probability that the slow ``eventual consistency propagate'' method is called so that the overall read latency can be reduced.

\subsection{Eventually consistent write}
A critical reason that chain replication storage systems are generally slow in write operations is that the write operation needs to go through all the nodes in the chain. While this guarantees strong consistency, the latency is also large when nodes are placed spatially distant to each other. However, if strong consistency is not a must, one can choose to write new data to any node in the chain instead of writing to the head node. In CRAQamo, we allow the user to write to any node and safely check whether there are other writes performed on other nodes when the write operation is being performed. Note that write operations happening almost concurrently on multiple nodes rarely happens, so the synchronization can take slightly longer time and it will not critically affect the overall write performance.

When an eventually consistent write operation is performed on a node. The node first takes the input object, writes it locally and attaches a timestamp to the updated object. There is a possibility that when it writes the object, another write operation of the same object is performed on another node, thus the written object is no longer the newest when the current node finishes writing. To make sure that the newly written data is the newest, a safety check is done when the write finishes. The current node compares the timestamp of the newly written object with the timestamps of the object on all other nodes. Once there are $W$ other nodes agree that the current node has the newer version of object, the current node signals the user that the write is successful and uses ``eventual consistency propagate'' to broadcast the newly written object to all other nodes. If any of the $W$ nodes disagrees that the current node has the newer version of object, ``eventual consistency propagate'' is also executed so that the newer object can be synchronized among all nodes. After synchronization, the current node signals the user that the write is successful. 


\subsection{Implementation}
Our prototype implementation of CRAQamo was implemented in approximately 3700 lines of C++,
built upon the a prototype implementation of CRAQ implemented in approximately 3000 lines of C++.
Like CRAQ, CRAQamo uses the Tame \cite{tame} extension to the SFS asynchronous I/O and RPC libraries \cite{sfs} and all network functionality between CRAQamo RPC nodes is exposed via Sun RPC interfaces.
Unlike CRAQ, CRAQamo also uses the built in C++ multithreading library.
To implement the broadcast reads and writes for consistency checks, CRAQamo needs to spin up multiple threads, and wait until $w$ of them complete their calls before returning.
Even after returning, however, CRAQamo needs to continue the consistency checks for the nodes that have not completed.
This proved too difficult of a pattern to express in Tame, so we instead built our own manner of multithreading for these checks.
However, for all other asynchronous calls, we used Tame to decrease code complexity.

Our integration with ZooKeeper was provided with by the expansion of CRAQ, and was integrated in the same way, with CRAQamo nodes able to query the same ZooKeeper files as CRAQ nodes.
Furthermore, expansion of CRAQ gave us free chain node functionality and the ability to handle membership changes dynamically.
Because data is stored in the same manner as CRAQ, and because no node has special knowledge in CRAQamo, CRAQ's algorithm for membership changes proves sufficient for CRAQamo.
